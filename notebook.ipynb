{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code extracts audio from a video <br>and generates subtitles in SRT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import tempfile\n",
    "\n",
    "def extract_audio(video_path, output_path):\n",
    "    \"\"\"Extract audio from video file\"\"\"\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(output_path)\n",
    "    video.close()\n",
    "\n",
    "def transcribe_audio_segment(audio_segment, recognizer):\n",
    "    \"\"\"Transcribource)\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                return \"\"\n",
    "            except sr.RequestError:\n",
    "                return \"[Error: Could not request results]\"\n",
    "            finally:\n",
    "     e a single audio segment\"\"\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:\n",
    "        audio_segment.export(temp_audio.name, format='wav')\n",
    "        with sr.AudioFile(temp_audio.name) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                return \"\"\n",
    "            except sr.RequestError:\n",
    "                return \"[Error: Could not request results]\"\n",
    "            finally:\n",
    "                os.unlink(temp_audio.name)\n",
    "\n",
    "def generate_subtitles(video_path, output_srt_path, min_silence_len=500, silence_thresh=-40):\n",
    "    \"\"\"Generate subtitles from video and save as SRT file\"\"\"\n",
    "    # Create temporary audio file\n",
    "    temp_audio_path = 'temp_audio.wav'\n",
    "    \n",
    "    try:\n",
    "        # Extract audio from video\n",
    "        print(\"Extracting audio from video...\")\n",
    "        extract_audio(video_path, temp_audio_path)\n",
    "        \n",
    "        # Load audio file\n",
    "        print(\"Processing audio...\")\n",
    "        audio = AudioSegment.from_wav(temp_audio_path)\n",
    "        \n",
    "        # Split audio on silence\n",
    "        chunks = split_on_silence(\n",
    "            audio,\n",
    "            min_silence_len=min_silence_len,\n",
    "            silence_thresh=silence_thresh\n",
    "        )\n",
    "        \n",
    "        # Initialize speech recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "        \n",
    "        # Create SRT file\n",
    "        print(\"Generating subtitles...\")\n",
    "        with open(output_srt_path, 'w', encoding='utf-8') as srt_file:\n",
    "            for i, chunk in enumerate(chunks, 1):\n",
    "                # Calculate timestamps\n",
    "                start_time = sum(len(c) for c in chunks[:i-1])\n",
    "                end_time = start_time + len(chunk)\n",
    "                \n",
    "                # Format timestamps for SRT file\n",
    "                start_timestamp = f\"{start_time//60000:02d}:{(start_time//1000)%60:02d}:{start_time%1000:03d}\"\n",
    "                end_timestamp = f\"{end_time//60000:02d}:{(end_time//1000)%60:02d}:{end_time%1000:03d}\"\n",
    "                \n",
    "                # Transcribe audio chunk\n",
    "                text = transcribe_audio_segment(chunk, recognizer)\n",
    "                \n",
    "                # Write to SRT file\n",
    "                if text:\n",
    "                    srt_file.write(f\"{i}\\n\")\n",
    "                    \n",
    "                    srt_file.write(f\"{start_timestamp} --> {end_timestamp}\\n\")\n",
    "                    srt_file.write(f\"{text}\\n\\n\")\n",
    "        \n",
    "        print(f\"Subtitles generated successfully! Saved to {output_srt_path}\")\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        if os.path.exists(temp_audio_path):\n",
    "            os.remove(temp_audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from video...\n",
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Processing audio...\n",
      "Generating subtitles...\n",
      "Subtitles generated successfully! Saved to 2024-11-02 19-57-47.srt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_path = '2024-11-02 19-57-47.mkv'\n",
    "output_srt_path = video_path.rsplit('.', 1)[0] + '.srt'\n",
    "\n",
    "generate_subtitles(video_path, output_srt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To extract the SRT file created<br>of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "def clean_srt(srt_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and extract text content from SRT file\n",
    "    \"\"\"\n",
    "    with open(srt_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Remove SRT indices and timestamps\n",
    "    pattern = r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n'\n",
    "    cleaned_content = re.sub(pattern, '', content)\n",
    "    \n",
    "    # Remove empty lines and clean up spacing\n",
    "    cleaned_content = '\\n'.join(line.strip() for line in cleaned_content.split('\\n') if line.strip())\n",
    "    \n",
    "    return cleaned_content\n",
    "\n",
    "def create_analysis_prompt() -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Create a detailed prompt template for video content analysis\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "    You are an expert content analyst. Analyze the following video transcript and answer these specific questions.\n",
    "    Please provide detailed, factual responses based solely on the content provided.\n",
    "    \n",
    "    TRANSCRIPT:\n",
    "    {text}\n",
    "    \n",
    "    Please analyze the content and answer the following questions:\n",
    "    1. What is the main topic or theme of this video?\n",
    "    2. Who are the key speakers or participants mentioned (if any)?\n",
    "    3. What are the 3-5 most important points discussed?\n",
    "    4. Are there any significant statistics or numerical data mentioned?\n",
    "    5. What practical advice or recommendations are given (if any)?\n",
    "    6. What are the key conclusions or takeaways?\n",
    "    7. Are there any notable quotes or memorable statements?\n",
    "    8. What technical terms or specialized vocabulary are used?\n",
    "    9. What problems or challenges are discussed?\n",
    "    10. What solutions or resolutions are proposed?\n",
    "\n",
    "    Format your response as a Python dictionary with these exact keys:\n",
    "    - main_topic\n",
    "    - speakers\n",
    "    - key_points\n",
    "    - statistics\n",
    "    - recommendations\n",
    "    - conclusions\n",
    "    - notable_quotes\n",
    "    - technical_terms\n",
    "    - challenges\n",
    "    - solutions\n",
    "\n",
    "    Each value should be either a string or a list of strings, as appropriate.\n",
    "    Ensure the response is properly formatted for direct parsing into a Python dictionary.\n",
    "    If any information is not available, use an empty string or empty list as appropriate.\n",
    "    \"\"\"\n",
    "    \n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "def analyze_content(api_key: str, content: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze content using Gemini and return structured results\n",
    "    \"\"\"\n",
    "    # Initialize Gemini LLM\n",
    "    llm = GoogleGenerativeAI(\n",
    "        model=\"models/gemini-1.5-flash\",\n",
    "        google_api_key=api_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    # Create and run the chain\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=create_analysis_prompt()\n",
    "    )\n",
    "    \n",
    "    # Get response\n",
    "    response = chain.run(text=content)\n",
    "    \n",
    "    # Convert string response to dictionary (safely)\n",
    "    try:\n",
    "        # Clean up the response string to ensure it's valid Python syntax\n",
    "        response = response.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "        result_dict = eval(response)\n",
    "        \n",
    "        # Ensure all expected keys are present\n",
    "        expected_keys = [\n",
    "            'main_topic', 'speakers', 'key_points', 'statistics',\n",
    "            'recommendations', 'conclusions', 'notable_quotes',\n",
    "            'technical_terms', 'challenges', 'solutions'\n",
    "        ]\n",
    "        \n",
    "        for key in expected_keys:\n",
    "            if key not in result_dict:\n",
    "                result_dict[key] = [] if key in ['key_points', 'statistics', 'recommendations', \n",
    "                                               'notable_quotes', 'technical_terms', 'challenges', \n",
    "                                               'solutions'] else \"\"\n",
    "        \n",
    "        return result_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing LLM response: {e}\")\n",
    "        return {key: [] if key in ['key_points', 'statistics', 'recommendations', \n",
    "                                 'notable_quotes', 'technical_terms', 'challenges', \n",
    "                                 'solutions'] else \"\" for key in expected_keys}\n",
    "\n",
    "def flatten_dict_for_pandas(d: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Flatten nested dictionary/list structures for pandas DataFrame\n",
    "    \"\"\"\n",
    "    flattened = {}\n",
    "    \n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, list):\n",
    "            # Join list items with '|' for better CSV readability\n",
    "            flattened[key] = '|'.join(str(item) for item in value)\n",
    "        else:\n",
    "            flattened[key] = str(value)\n",
    "    \n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning SRT content...\n",
      "Analyzing content with Gemini...\n",
      "Analysis results saved to document.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_topic</th>\n",
       "      <th>speakers</th>\n",
       "      <th>key_points</th>\n",
       "      <th>statistics</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>conclusions</th>\n",
       "      <th>notable_quotes</th>\n",
       "      <th>technical_terms</th>\n",
       "      <th>challenges</th>\n",
       "      <th>solutions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creating a desktop application to retrieve sub...</td>\n",
       "      <td>The speaker is not explicitly identified, but ...</td>\n",
       "      <td>The application retrieves subtitles from a You...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The application is a simple but useful tool fo...</td>\n",
       "      <td></td>\n",
       "      <td>PyWebView|requests|json|pyperclip|langchain|Ja...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          main_topic  \\\n",
       "0  Creating a desktop application to retrieve sub...   \n",
       "\n",
       "                                            speakers  \\\n",
       "0  The speaker is not explicitly identified, but ...   \n",
       "\n",
       "                                          key_points statistics  \\\n",
       "0  The application retrieves subtitles from a You...              \n",
       "\n",
       "  recommendations                                        conclusions  \\\n",
       "0                  The application is a simple but useful tool fo...   \n",
       "\n",
       "  notable_quotes                                    technical_terms  \\\n",
       "0                 PyWebView|requests|json|pyperclip|langchain|Ja...   \n",
       "\n",
       "  challenges solutions  \n",
       "0                       "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The api key of gemini\n",
    "api_key = 'YOUR_API_KEY'\n",
    "\n",
    "# Get input file path\n",
    "srt_path = '2024-11-02 19-57-47.srt'\n",
    "output_path = 'document.csv'\n",
    "\n",
    "# Process the content\n",
    "print(\"Cleaning SRT content...\")\n",
    "cleaned_content = clean_srt(srt_path)\n",
    "\n",
    "print(\"Analyzing content with Gemini...\")\n",
    "analysis_results = analyze_content(api_key, cleaned_content)\n",
    "\n",
    "# Flatten the results for pandas\n",
    "flattened_results = flatten_dict_for_pandas(analysis_results)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame([flattened_results])\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Analysis results saved to {output_path}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
